import os
import csv
import openai
from flask import Flask, request, jsonify
from flask_cors import CORS
from pathlib import Path

app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}})

# –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
openai.api_key = os.getenv("OPENAI_API_KEY")

# –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
knowledge_base = []
try:
    kb_path = Path(__file__).resolve().parent / "knowledge_base.csv"
    with open(kb_path, encoding="utf-8") as f:
        reader = csv.DictReader(f, delimiter=";")
        for row in reader:
            knowledge_base.append({"question": row["question"], "answer": row["answer"]})
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {e}")

# –ü–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
def simple_search(user_question):
    return [
        item for item in knowledge_base
        if user_question.lower() in item["question"].lower()
    ][:3]

# –ì–ª–∞–≤–Ω—ã–π –º–∞—Ä—à—Ä—É—Ç –¥–ª—è —á–∞—Ç–∞
@app.route("/ask", methods=["POST", "OPTIONS"])
def ask():
    if request.method == "OPTIONS":
        return '', 200

    data = request.get_json()
    user_question = data.get("question", "")
    print("üì• –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:", user_question)

    context_items = simple_search(user_question)
    context = "\n\n".join([f"–í–æ–ø—Ä–æ—Å: {i['question']}\n–û—Ç–≤–µ—Ç: {i['answer']}" for i in context_items])
    print("üìö –ö–æ–Ω—Ç–µ–∫—Å—Ç:", context)

    if context.strip():
        prompt = f"–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ 44-–§–ó. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∏–∂–µ, —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å:\n\n{context}\n\n–í–æ–ø—Ä–æ—Å: {user_question}"
    else:
        prompt = f"–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ 44-–§–ó. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–Ω–æ:\n\n–í–æ–ø—Ä–æ—Å: {user_question}"

    try:
        print("üß™ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ OpenAI...")
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=150,
            temperature=0.7,
        )
        answer = response.choices[0].message.content
        return jsonify({"answer": answer})

    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞ OpenAI:", e)
        return jsonify({"error": str(e)}), 500

# –¢–µ—Å—Ç–æ–≤—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ API-–∫–ª—é—á–∞
@app.route("/check-key", methods=["GET"])
def check_key():
    try:
        models = openai.models.list()
        model_names = [m.id for m in models.data]
        return jsonify({"status": "ok", "models": model_names})
    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–ª—é—á–∞:", e)
        return jsonify({"status": "error", "message": str(e)}), 401

# –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    app.run(debug=True, host='0.0.0.0', port=port)
