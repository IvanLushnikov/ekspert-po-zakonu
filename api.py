import os
import csv
import openai
import numpy as np
import pandas as pd
from flask import Flask, request, jsonify, make_response
from flask_cors import CORS
from pathlib import Path
from numpy.linalg import norm

app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}})

openai.api_key = os.getenv("OPENAI_API_KEY")

# === –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã —Å embedding ===
try:
    kb_path = Path(__file__).resolve().parent / "knowledge_base_with_embeddings.pkl"
    df_kb = pd.read_pickle(kb_path)
    df_kb["embedding"] = df_kb["embedding"].apply(np.array)
    print("üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —Å embedding –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {e}")
    df_kb = pd.DataFrame(columns=["question", "answer", "embedding"])

# === –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è embedding ===
def get_embedding(text, model="text-embedding-3-small"):
    text = text.replace("\n", " ")
    response = openai.Embedding.create(input=[text], model=model)
    return np.array(response.data[0].embedding)

# === –ü–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ ===
def search_similar_questions(question, top_n=3):
    query_emb = get_embedding(question)
    df_kb["similarity"] = df_kb["embedding"].apply(lambda x: np.dot(x, query_emb) / (norm(x) * norm(query_emb)))
    top = df_kb.sort_values("similarity", ascending=False).head(top_n)
    return top[["question", "answer"]].to_dict(orient="records")

# === –û—Å–Ω–æ–≤–Ω–æ–π –º–∞—Ä—à—Ä—É—Ç ===
@app.route("/ask", methods=["POST", "OPTIONS"])
def ask():
    if request.method == "OPTIONS":
        # –Ø–≤–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ preflight-–∑–∞–ø—Ä–æ—Å
        response = make_response('', 200)
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
        response.headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'
        return response

    data = request.get_json()
    user_question = data.get("question", "")
    print("üì• –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:", user_question)

    try:
        context_items = search_similar_questions(user_question)
    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ embedding:", e)
        context_items = []

    context = "\n\n".join([f"–í–æ–ø—Ä–æ—Å: {i['question']}\n–û—Ç–≤–µ—Ç: {i['answer']}" for i in context_items])
    print("üìö –ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞–π–¥–µ–Ω:", context != "")

    if context.strip():
        prompt = f"–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ 44-–§–ó. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∏–∂–µ, —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å:\n\n{context}\n\n–í–æ–ø—Ä–æ—Å: {user_question}"
    else:
        prompt = f"–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ 44-–§–ó. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–Ω–æ:\n\n–í–æ–ø—Ä–æ—Å: {user_question}"

    try:
        print("üß™ –ó–∞–ø—Ä–æ—Å –≤ OpenAI...")
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=300,
            temperature=0.7,
        )
        answer = response.choices[0].message.content
        response = jsonify({"answer": answer})
        response.headers.add("Access-Control-Allow-Origin", "*")
        return response

    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞ OpenAI:", e)
        response = jsonify({"error": str(e)})
        response.headers.add("Access-Control-Allow-Origin", "*")
        return response, 500

# === –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–∞ ===
@app.route("/check-key", methods=["GET"])
def check_key():
    try:
        models = openai.models.list()
        return jsonify({"status": "ok", "models": [m.id for m in models.data]})
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 401

# === –ó–∞–ø—É—Å–∫ –ª–æ–∫–∞–ª—å–Ω–æ ===
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    app.run(debug=True, host='0.0.0.0', port=port)
